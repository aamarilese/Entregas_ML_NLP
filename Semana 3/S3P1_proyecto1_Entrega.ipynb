{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w75FGynzwqO3"
   },
   "source": [
    "# Informe Modelo Predictivo Popularidad de Canciones en Spotify\n",
    "<p style=\"text-align: justify;\">\n",
    "Este informe presenta el desarrollo de un modelo de aprendizaje automático, cuyo ibjetivo es predecir el nivel de popularidad de canciones en Spotify. A lo largo del documento se describen las etapas fundamentales del proceso, incluyendo el preprocesamiento de datos, la selección y calibración del modelo, el entrenamiento y evaluación del rendimiento, y la disponibilización del modelo mediante una API. El enfoque se basa en el uso de modelos de árboles de decisión y ensamblajes, implementados con Python.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsRegressor\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'catboost'"
     ]
    }
   ],
   "source": [
    "## Librerias a Importar\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Manipulación de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "# Modelado y evaluación\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Modelos base\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    BaggingRegressor,\n",
    "    StackingRegressor\n",
    ")\n",
    "from sklearn.linear_model import (\n",
    "    ElasticNetCV, \n",
    "    RidgeCV, \n",
    "    LassoCV, \n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "# Preprocesamiento y selección de características\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiB84TdJwqO4"
   },
   "source": [
    "## Preprocesamiento de Datos\n",
    "<p style=\"text-align: justify;\">\n",
    "En este proyecto se usaró el conjunto de datos de datos de popularidad en canciones, donde cada observación representa una canción y se tienen variables como: duración de la canción, acusticidad y tempo, entre otras. El objetivo es predecir qué tan popular es la canción.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2025/main/datasets/dataTrain_Spotify.csv')\n",
    "dataTesting = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2025/main/datasets/dataTest_Spotify.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(dataTraining.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "A continuación, se valida la dimensión de los datos, los tipos de variables y se indentifica la existencia de valores faltantes y duplicados. Según los resultados, se identificaron valores duplicados y algunas variables string y categoricas. De igual forma se identifica que existen variables tipo <code>int64</code> y <code>float64</code>, los cuales podrían generan un uso importante de la memoria.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisión inicial de datos\n",
    "print(\"Dimensión de los datos de entrenamiento:\", dataTraining.shape)\n",
    "\n",
    "if dataTraining.isnull().sum().sum() > 0: # Verifica si hay valores nulos\n",
    "    print(\"\\nValores nulos en los datos de entrenamiento:\")\n",
    "    print(dataTraining.isnull().sum())\n",
    "else:\n",
    "    print(\"\\nNo hay valores nulos en los datos de entrenamiento.\")\n",
    "\n",
    "print(\"\\nNúmero de canciones duplicadas según Track_ID:\")\n",
    "print(dataTraining['track_id'].duplicated().sum())\n",
    "\n",
    "print(\"\\nTipos de variables en la base de datos:\")\n",
    "print(dataTraining.dtypes.unique())\n",
    "\n",
    "print(\"\\nVariables string y categóricas en la base de datos:\")\n",
    "print(dataTraining.select_dtypes(include=['object', 'bool']).info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "A continuación, se realizarán algunos ajustes a la base de datos. En primer lugar se optimiza el uso de memoria del dataset <code>dataTraining</code> ajustando los tipos de datos según su contenido. Este procedimiento es relevante porque reduce significativamente el consumo de memoria, mejorando la eficiencia del procesamiento y el rendimiento del modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de duplicados\n",
    "dataTraining = dataTraining.drop_duplicates(subset='track_id', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación tipológica de variables con el objetivo de reducir el uso de memoria\n",
    "# Se recomienda usar float32 en lugar de float64 y int32 en lugar de int64\n",
    "for col in dataTraining.columns:\n",
    "    col_type = dataTraining[col].dtype\n",
    "\n",
    "    if col_type == 'float64':\n",
    "        dataTraining[col] = dataTraining[col].astype('float32')\n",
    "    elif col_type == 'int64':\n",
    "        dataTraining[col] = dataTraining[col].astype('int32')\n",
    "    elif col_type == 'bool':\n",
    "        dataTraining[col] = dataTraining[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de variables string\n",
    "for col in ['Unnamed: 0']:\n",
    "    if col in dataTraining.columns: dataTraining.drop(columns=col, inplace=True)\n",
    "    if col in dataTesting.columns: dataTesting.drop(columns=col, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar columnas categóricas\n",
    "for col in ['artists', 'album_name', 'track_genre']:\n",
    "    combined = pd.concat([dataTrain[col], dataTest[col]], axis=0).astype(str)\n",
    "    encoder = LabelEncoder().fit(combined)\n",
    "    dataTrain[col + '_n'] = encoder.transform(dataTrain[col].astype(str))\n",
    "    dataTest[col + '_n'] = encoder.transform(dataTest[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de variables nuevas\n",
    "# Se crean variables que pueden ser útiles para el modelo\n",
    "for df in [dataTraining, dataTesting]:\n",
    "    df['track_name_length'] = df['track_name'].apply(lambda x: len(str(x)))\n",
    "    df['tempo_density'] = df['tempo'] / df['duration_ms']\n",
    "    df['energy_danceability'] = df['energy'] * df['danceability']\n",
    "    df['acousticness_bin'] = (df['acousticness'] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Selección de columnas y escalado\n",
    "drop_cols = ['track_id', 'track_name', 'artists', 'album_name', 'track_genre']\n",
    "features = dataTraining.drop(columns=drop_cols + ['popularity']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores infinitos por NaN y luego llenar NaN con la mediana\n",
    "for df in [dataTraining, dataTesting]:\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(df.median(numeric_only=True), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de datos\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(dataTraining[features])\n",
    "XTesting = scaler.transform(dataTesting[features])\n",
    "y = dataTraining['popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "Adicionalmente, como parte del pre procesamiento de datos se realiza una selección de variables utilizando un modelo de Extreme Gradient Boosting, \"XGB\"  como base. Esta técnica reduce la dimensionalidad del conjunto de datos y mejora la eficiencia del modelo sin comprometer su capacidad predictiva.. De acuerdo con los resultados obtenidos se seleccionaron 13 variables de las cuales 10 vienen de la base de datos original y 3 fueron creadas en pasos previos.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características con XGBRegressor\n",
    "selector = SelectFromModel(XGBRegressor(n_estimators=100, random_state=42))\n",
    "selector.fit(X, y)\n",
    "X_sel = selector.transform(X)\n",
    "X_test_sel = selector.transform(XTesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables predictoras\n",
    "selected_columns = X.columns[selector.get_support()].tolist()\n",
    "print(tabulate([[col] for col in selected_columns], headers=[\"Columnas Seleccionadas\"], tablefmt=\"psql\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de Estadísticas Descriptivas\n",
    "<p style=\"text-align: justify;\">\n",
    "En esta sección se realiza un análisis descriptivo de la base de datos. Se presentan las principales estadísticas descriptivas, así como histogramas, correlaciones y visualización de valores atípicos.<p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estilos de los gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# Histograma de variables numéricas\n",
    "dataTraining.select_dtypes(include=np.number).hist(bins=30, figsize=(18, 12), color='skyblue', edgecolor='black')\n",
    "plt.suptitle(\"Distribución de variables numéricas\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mapa de calor de correlación\n",
    "plt.figure(figsize=(14, 10))\n",
    "corr = dataTraining.select_dtypes(include=np.number).corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
    "plt.title(\"Matriz de Correlación\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# --- 3. Boxplots para identificar outliers ---\n",
    "for col in dataTraining.select_dtypes(include=np.number).columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.boxplot(x=dataTraining[col], color='lightgreen')\n",
    "    plt.title(f\"Boxplot: {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categóricas\n",
    "cat_cols = dataTraining.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "# Visualizar la cantidad de valores únicos por variable categórica\n",
    "print(\"Valores únicos por variable categórica:\")\n",
    "for col in cat_cols:\n",
    "    print(f\"{col}: {dataTraining[col].nunique()} valores únicos\")\n",
    "\n",
    "# Distribución de frecuencia de las principales categorías\n",
    "for col in cat_cols:\n",
    "    if dataTraining[col].nunique() <= 50:  # Limita el análisis a columnas con un número manejable de categorías\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        dataTraining[col].value_counts().head(20).plot(kind='bar', color='cornflowerblue')\n",
    "        plt.title(f\"Top 20 valores de {col}\")\n",
    "        plt.ylabel(\"Frecuencia\")\n",
    "        plt.xlabel(col)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "# Popularidad promedio por categoría\n",
    "for col in cat_cols:\n",
    "    if 'popularity' in dataTraining.columns and dataTraining[col].nunique() <= 50:\n",
    "        popularity_by_cat = dataTraining.groupby(col)['popularity'].mean().sort_values(ascending=False).head(20)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(x=popularity_by_cat.values, y=popularity_by_cat.index, palette=\"viridis\")\n",
    "        plt.title(f\"Popularidad promedio por {col} (Top 20)\")\n",
    "        plt.xlabel(\"Popularidad Promedio\")\n",
    "        plt.ylabel(col)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por 'track_genre' y calcular las medias de las columnas seleccionadas\n",
    "perfil_generos = dataTraining.groupby('track_genre')[dataTraining.select_dtypes(include=np.number).columns].mean().round(2).sort_values('popularity', ascending=False)\n",
    "\n",
    "# Mostrar el perfil\n",
    "print(perfil_generos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación de Datos en Entrenamiento y Prueba\n",
    "<p style=\"text-align: justify;\">\n",
    "Se dividió el conjunto de datos en dos subconjuntos: uno de entrenamiento y otro de validación, utilizando una proporción del 80 % para entrenamiento y 20 % para validación.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección y Calibración del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Selección del Modelo Predictivo y Justificación\n",
    "<p style=\"text-align: justify;\">\n",
    "A partir de un proceso iterativo de prueba y error con diferentes modelos predictivos, se eligió el modelo de Satcking como el modelo definitivo para participar en la competencia de predicción del nivel de popularidad de las canciones en Spotify. \n",
    "\n",
    "Para este modelo de stacking, seleccionamos varios modelos base con estructuras distintas para que aportaran diversidad y evitar que todos cometieran los mismos errores. Incluimos:\n",
    "\n",
    "- Un `SVR` con núcleo `rbf`, ideal para capturar relaciones no lineales en casos más simples.\n",
    "- Ensambles basado en árboles como `RandomForestRegressor`, `ExtraTreesRegressor` y `BaggingRegressor`, que son modelos robustos y generalizan bien.\n",
    "- Modelos de boosting como `XGBoost`, `LightGBM` y `CatBoost`, conocidos por su gran desempeño en competencias.\n",
    "- Modelos lineales (`ElasticNet`, `RidgeCV`, `LassoCV`), que son útiles para regularización y relaciones más simples.\n",
    "- Y un `KNeighborsRegressor`, que puede ser útil cuando hay patrones locales en los datos.\n",
    "\n",
    "Inicialmente, intentamos usar `GridSearchCV` para encontrar los mejores hiperparámetros de cada modelo, pero resultó demasiado costoso en tiempo y recursos. Además, los resultados no mejoraron mucho respecto a los parámetros definidos manualmente, así que optamos por dejar configuraciones que ya sabíamos que funcionaban bien según la experiencia y la documentación de cada modelo.\n",
    "\n",
    "Esta decisión nos permitió tener un entrenamiento más rápido sin sacrificar el rendimiento del modelo.\n",
    "\n",
    "A continuación se presentarán el procedimiento de calibración, entrenamiento, predicción y evaluación del desempeño del mismo.\n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Calibración de Modelos Individuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrar Random Forest\n",
    "rf_params = {'n_estimators': [100, 200], 'max_depth': [20, 30]}\n",
    "rf_grid = GridSearchCV(RandomForestRegressor(random_state=42), rf_params, cv=3)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "best_rf = rf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrar Gradient Boosting\n",
    "gb_params = {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.075], 'max_depth': [3, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingRegressor(random_state=42), gb_params, cv=3)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "best_gb = gb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrar XGBoost\n",
    "xgb_params = {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.075], 'max_depth': [3, 5]}\n",
    "xgb_grid = GridSearchCV(XGBRegressor(random_state=42), xgb_params, cv=3)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "best_xgb = xgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Entrenamiento del Modelo Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos base\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=200, learning_rate=0.075, max_depth=5, random_state=42)),\n",
    "    ('xgb', XGBRegressor(n_estimators=200, learning_rate=0.075, max_depth=5, random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo de stacking\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=GradientBoostingRegressor(n_estimators=100, learning_rate=0.05, max_depth=3),\n",
    "    passthrough=True,\n",
    "    n_jobs=-1,\n",
    "    cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo de stacking con los datos transformados\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de validación\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Calcular la raíz del error cuadrático medio (RMSE)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"RMSE validación local: {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo de stacking con los datos transformados\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Generar predicciones finales en el conjunto de prueba\n",
    "test_pred = stacking_model.predict(X_test_sel)\n",
    "submission = pd.DataFrame({'ID': dataTesting.index, 'popularity': test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el archivo de envío para Kaggle\n",
    "submission.to_csv('test_submission_file.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Evaluación del Desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {RMSE:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disponibilización del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso para asegurar la disponibilidad del modelo se estructuró en tres pasos principales:\n",
    "\n",
    "#### Construcción y almacenamiento del modelo\n",
    "Se construyó un modelo y se almacenó en un archivo .pkl.\n",
    "Debido a las limitaciones de tamaño en GitHub, no se utilizó el modelo de la competencia. En su lugar, se implementó un modelo de Random Forest con 50 muestras, permitiendo que el archivo pudiera ser subido a la plataforma.\n",
    "\n",
    "#### Creación de la función en un archivo .py\n",
    "El archivo .pkl generado fue utilizado para crear una función dentro de un archivo .py.\n",
    "Esta función fue diseñada para ser importada posteriormente, facilitando la modularidad y reutilización del código.\n",
    "\n",
    "#### Desarrollo de la API\n",
    "Finalmente, se construyó la API en otro archivo .py.\n",
    "Esta API importa la función previamente creada y configura un método GET, el cual recibe los parámetros necesarios para ejecutar la predicción del modelo de forma sencilla y estructurada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Servidor utilizado\n",
    "\n",
    "<img src=\"Imagenes_Disponibilidad/Dispo_1.png\">\n",
    "<img src=\"Imagenes_Disponibilidad/Dispo_2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API: http://54.242.6.90:5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6KwkVtXm8OUp2XffN5k7lY</td>\n",
       "      <td>Hillsong Worship</td>\n",
       "      <td>No Other Name</td>\n",
       "      <td>No Other Name</td>\n",
       "      <td>440247</td>\n",
       "      <td>False</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.598</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.00511</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>148.014</td>\n",
       "      <td>4</td>\n",
       "      <td>world-music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dp5I5MJ8bQQHDoFaNRFtX</td>\n",
       "      <td>Internal Rot</td>\n",
       "      <td>Grieving Birth</td>\n",
       "      <td>Failed Organum</td>\n",
       "      <td>93933</td>\n",
       "      <td>False</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.997</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.586</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.00521</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>122.223</td>\n",
       "      <td>4</td>\n",
       "      <td>grindcore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id           artists      album_name      track_name  \\\n",
       "0  6KwkVtXm8OUp2XffN5k7lY  Hillsong Worship   No Other Name   No Other Name   \n",
       "1  2dp5I5MJ8bQQHDoFaNRFtX      Internal Rot  Grieving Birth  Failed Organum   \n",
       "\n",
       "   duration_ms  explicit  danceability  energy  key  loudness  mode  \\\n",
       "0       440247     False         0.369   0.598    7    -6.984     1   \n",
       "1        93933     False         0.171   0.997    7    -3.586     1   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \\\n",
       "0       0.0304       0.00511             0.000     0.176   0.0466  148.014   \n",
       "1       0.1180       0.00521             0.801     0.420   0.0294  122.223   \n",
       "\n",
       "   time_signature  track_genre  \n",
       "0               4  world-music  \n",
       "1               4    grindcore  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTesting.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrada 0:\n",
    "\n",
    "<img src=\"Imagenes_Disponibilidad/Dispo_3.png\">\n",
    "\n",
    "#### Entrada 1:\n",
    "\n",
    "<img src=\"Imagenes_Disponibilidad/Dispo_4.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
