{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8f889c",
   "metadata": {},
   "source": [
    "### üìä **Informe: Modelo de Clasificaci√≥n de G√©nero de Pel√≠culas**\n",
    "\n",
    "### üë• Integrantes\n",
    "- Miguel Mateo Sandoval Torres  \n",
    "- Diego Dayan Ni√±o P√©rez  \n",
    "- Camilo Andr√©s Fl√≥rez Esquivel  \n",
    "- Andrea Amariles Escobar  \n",
    "\n",
    "### üìö Curso\n",
    "**Machine Learning y Procesamiento de Lenguaje Natural**\n",
    "\n",
    "### üóìÔ∏è Fecha\n",
    "**Mayo de 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38915ce6",
   "metadata": {},
   "source": [
    "### **Introducci√≥n** <br>\n",
    "<p style=\"text-align: justify;\">\n",
    "Este informe presenta el desarrollo de un modelo de aprendizaje autom√°tico, cuyo objetivo es predecir la probabilidad de que una pel√≠cula pertenezca a un g√©nero en particular. A lo largo del documento se describen las etapas fundamentales del proceso, incluyendo el preprocesamiento de datos, la selecci√≥n y calibraci√≥n del modelo, el entrenamiento y evaluaci√≥n del rendimiento del mismo, al igual que m√©tricas comparativas con versiones alternativas, con el objetivo de evidenciar el proceso de selecci√≥n del modelo final. Finalmente, se presenta el procedimiento de disponibilizaci√≥n del modelo predictivo mediante una API.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd60e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaci√≥n librer√≠as\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62090e49",
   "metadata": {},
   "source": [
    "### **Carga y Preprocesamiento de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65855692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTraining.zip', encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv('https://github.com/albahnsen/MIAD_ML_and_NLP/raw/main/datasets/dataTesting.zip', encoding='UTF-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9215893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e716777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n datos de test\n",
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisi√≥n general de los datos\n",
    "nulos = dataTraining.isnull().sum()               # Busqueda de valores nulos\n",
    "duplicados = dataTraining.duplicated().sum()      # Busqueda de valores repetidos\n",
    "titulos_unicos = dataTraining['title'].nunique()  # T√≠tulos √∫nicos de pel√≠culas\n",
    "dataTraining.info()                               # Informaci√≥n general de los datos\n",
    "\n",
    "print(f'Valores nulos:\\n{nulos}')\n",
    "print(f'\\nValores duplicados: {duplicados}')\n",
    "print(f'\\nCantidad de t√≠tulos √∫nicos: {titulos_unicos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining['genres_list'] = dataTraining['genres'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8428bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de pel√≠culas por g√©nero\n",
    "frecuencia_generos = list(chain.from_iterable(dataTraining['genres_list']))\n",
    "conteo_generos = Counter(frecuencia_generos)\n",
    "\n",
    "sorted_genres = conteo_generos.most_common()\n",
    "genres, counts = zip(*sorted_genres)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(genres, counts, color='skyblue')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('G√©nero')\n",
    "plt.ylabel('Cantidad de pel√≠culas')\n",
    "plt.title('Frecuencia de g√©neros en el dataset')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Paso 5: A√±adir etiquetas a cada barra\n",
    "for bar, count in zip(bars, counts):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 5,\n",
    "             str(count), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5fac0",
   "metadata": {},
   "source": [
    "#### Definici√≥n de Funciones de Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializaci√≥n de herramientas\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Funci√≥n de preprocesamiento\n",
    "def preprocess_text_1(text):\n",
    "    if isinstance(text, str): # Asegurarse de que la entrada sea una cadena\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z\\s]', '', text) # Liempieza de caracteres diferentes a letras, sustitucion por \" \"\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and len(word) > 2] # Lematizaci√≥n y eliminaci√≥n de stopwords y palabras cortas\n",
    "        return ' '.join(tokens)\n",
    "    return '' # Manejar casos donde el texto no es una cadena"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b2089",
   "metadata": {},
   "source": [
    "### **Entrenamiento y Selecci√≥n del Modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80fe14",
   "metadata": {},
   "source": [
    "Se entrenaron y calibraron diferentes modelos predictivos. A continuaci√≥n se presentan tres modelos a partir de los cuales se eligi√≥ el que present√≥ el mejor desempe√±o:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63e70c",
   "metadata": {},
   "source": [
    "#### Modelo 1: Regresi√≥n Log√≠stica con NLTK y CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec867c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=1000)\n",
    "X_dtm_1 = vect.fit_transform(dataTraining['plot_clean_1'])\n",
    "X_dtm_1.shape\n",
    "\n",
    "# Codificaci√≥n de etiquetas de salida (g√©neros)\n",
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))  # convertir a lista\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7023e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n en entrenamiento y prueba\n",
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm_1, y_genres, test_size=0.33, random_state=42)\n",
    "\n",
    "# Clasificador con Random Forest y One-vs-Rest\n",
    "clf = OneVsRestClassifier(LogisticRegression(n_jobs=-1, max_iter=1000, random_state=42))\n",
    "clf.fit(X_train, y_train_genres)\n",
    "\n",
    "# Predicci√≥n\n",
    "y_pred_genres = clf.predict_proba(X_test)\n",
    "\n",
    "# Evaluaci√≥n\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
