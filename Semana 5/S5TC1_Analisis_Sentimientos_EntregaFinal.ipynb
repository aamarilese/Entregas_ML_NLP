{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Análisis de sentimientos y técnicas de NLP\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre las diferentes técnicas para el procesamiento de lenguaje natural. El taller está constituido por 5 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción sentimientos de viajeros en Twitter\n",
    "\n",
    "En este taller se usará el conjunto de datos de sentimientos sobre distintas aerolíneas de EE.UU. provenientes de Twitter. Cada observación contiene si el sentimiento de los tweets es positivo, neutral o negativo teniendo en cuenta distintas variables como aerolínea y las razones de los sentimientos negativos (como \"retraso en el vuelo\" o \"servicio grosero\"). El objetivo es predecir el sentimiento asociado a cada tweet. Para más detalles pueden visitar el siguiente enlace: [datos](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías a Importar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de la información de archivo .zip\n",
    "tweets = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/Tweets.zip', index_col=0)\n",
    "\n",
    "# Visualización dataset\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión tamaño del cojunto de datos\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment\n",
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cuenta de tweets por cada sentimiento\n",
    "tweets['airline_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline\n",
       "United            3822\n",
       "US Airways        2913\n",
       "American          2759\n",
       "Southwest         2420\n",
       "Delta             2222\n",
       "Virgin America     504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cuenta de tweets por cada aerolínea\n",
    "tweets['airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot con cuenta de tweets por cada aerolínea y sentimiento\n",
    "pd.crosstab(index = tweets[\"airline\"],columns = tweets[\"airline_sentiment\"]).plot(kind='bar',figsize=(10, 6),alpha=0.5,rot=0,stacked=True,title=\"Sentiminetos por aerolínea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Datos en Conjunto de Entrenamiento y Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y de variable de interés (y)\n",
    "X = tweets['text']\n",
    "y = tweets['airline_sentiment'].map({'negative':0,'neutral':1,'positive':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Uso de CountVectorizer\n",
    "\n",
    "En la celda 1 creen un modelo de random forest con la libreria sklearn que prediga el sentimiento de los tweets usando los set de entrenamiento y test definidos anteriormente. Usen la función **CountVectorizer** y presenten el desempeño del modelo con la métrica del acurracy.\n",
    "\n",
    "Recuerden que el preprocesamiento que se haga sobre los datos de entrenamiento  (*.fit_transform()*) deben ser aplicado al set de test (*.transform()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de CountVectorizer para convertir el texto en una matriz de conteo\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceo de clases con SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamiento y predicción del modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "y_pred_rf = rf_model.predict(X_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy del modelo: 0.7649\n",
      "\n",
      " Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      3085\n",
      "           1       0.58      0.54      0.56       984\n",
      "           2       0.69      0.54      0.60       763\n",
      "\n",
      "    accuracy                           0.76      4832\n",
      "   macro avg       0.70      0.66      0.68      4832\n",
      "weighted avg       0.76      0.76      0.76      4832\n",
      "\n",
      "\n",
      " Matriz de confusión:\n",
      " [[2751  252   82]\n",
      " [ 347  536  101]\n",
      " [ 224  130  409]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo con el conjunto de test\n",
    "accuracy_RF = accuracy_score(y_test, y_pred_rf)\n",
    "Reporte_RF = classification_report(y_test, y_pred_rf)\n",
    "Matriz_conf_RF = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\" Accuracy del modelo: {accuracy_RF:.4f}\")\n",
    "print(\"\\n Reporte de clasificación:\\n\", Reporte_RF)\n",
    "print(\"\\n Matriz de confusión:\\n\", Matriz_conf_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción del Procedimiento y Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "En este punto se transforman los los textos de los tweets en una matriz numérica según la frecuencia de las palabras mediante CountVectorizer. Luego, se aplica SMOTE al conjunto de entrenamiento para balancear las clases minoritarias (<code>'neutral'</code> y <code>'positive'</code>). Con los datos balanceados, se entrena un modelo de Random Forest y, finalmente, se evalúa su desempeño en el conjunto de prueba utilizando métricas como accuracy, reporte de clasificación y matriz de confusión.<p>\n",
    "<p style=\"text-align: justify;\">\n",
    "En general modelo de obtuvo una exactitud del 76.49%. La clase 0 (<code>'negative'</code>) presentó una precisión de 0.83 y recall de 0.89, mientras que las clases 1 y 2 tuvieron un recall más bajo (0.54 en ambos casos). La matriz de confusión confirma más errores en estas últimas clases. El desbalance de datos podría influir en estos resultados.<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Eliminación de Stopwords\n",
    "<p style=\"text-align: justify;\">\n",
    "En la celda 2 creen un modelo de random forest con la libreria sklearn que prediga el sentimiento de los tweets usando los set de entrenamiento y test definidos anteriormente. Usen la función CountVectorizer, **eliminen stopwords** y presenten el desempeño del modelo con la métrica del acurracy.<p>\n",
    "\n",
    "Recuerden que el preprocesamiento que se haga sobre los datos de entrenamiento  (*.fit_transform()*) deben ser aplicado al set de test (*.transform()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de texto\n",
    "lemmatizer = WordNetLemmatizer()                                          # Inicializamos el lematizador\n",
    "def limpiar_texto(texto):\n",
    "    stop_words = set(stopwords.words('english'))                          # Lista de stopwords \n",
    "    tokens = wordpunct_tokenize(texto)                                    # Separamos el texto por palabras (tokens)\n",
    "        \n",
    "    tokens_filtrados = [p for p in tokens if p.lower() not in stop_words and p.isalpha()]   \n",
    "    return ' '.join(tokens_filtrados)\n",
    "\n",
    "# Aplicación de la función de limpieza a los textos\n",
    "X_train_limpio = X_train.apply(limpiar_texto)\n",
    "X_test_limpio = X_test.apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los textos a vectores usando CountVectorizer\n",
    "vectorizador = CountVectorizer()\n",
    "X_train_vec = vectorizador.fit_transform(X_train_limpio)\n",
    "X_test_vec = vectorizador.transform(X_test_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceo de clases con SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy del modelo combinado: 0.7671771523178808\n",
      "\n",
      " Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.90      0.86      3085\n",
      "           0       0.59      0.47      0.53       984\n",
      "           1       0.74      0.60      0.66       763\n",
      "\n",
      "    accuracy                           0.77      4832\n",
      "   macro avg       0.71      0.66      0.68      4832\n",
      "weighted avg       0.76      0.77      0.76      4832\n",
      "\n",
      "\n",
      " Matriz de confusión:\n",
      " [[2781  222   82]\n",
      " [ 437  466   81]\n",
      " [ 202  101  460]]\n"
     ]
    }
   ],
   "source": [
    "# Creamos y entrenamos el modelo Random Forest\n",
    "modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_rf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Hacemos predicciones y evaluamos el modelo\n",
    "predicciones = modelo_rf.predict(X_test_vec)\n",
    "\n",
    "# Métricas de desempeño\n",
    "accuracy_StopWords = accuracy_score(y_test, predicciones)\n",
    "reporte = classification_report(y_test, predicciones)\n",
    "matriz_conf = confusion_matrix(y_test, predicciones)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\" Accuracy del modelo combinado:\", accuracy_StopWords)\n",
    "print(\"\\n Reporte de clasificación:\\n\", reporte)\n",
    "print(\"\\n Matriz de confusión:\\n\", matriz_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Lematización con verbos\n",
    "\n",
    "En la celda 3 creen un modelo de random forest con la libreria sklearn que prediga el sentimiento de los tweets usando los set de entrenamiento y test definidos anteriormente. Usen la función CountVectorizer, **lematizen el texto con verbos** y presenten el desempeño del modelo con la métrica del acurracy.\n",
    "\n",
    "Recuerden que el preprocesamiento que se haga sobre los datos de entrenamiento  (*.fit_transform()*) deben ser aplicado al set de test (*.transform()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que limpie el texto\n",
    "# Quitamos palabras vacías y lematizamos las palabras restantes\n",
    "lemmatizer = WordNetLemmatizer()  # Inicializamos el lematizador\n",
    "def limpiar_texto(texto):\n",
    "    #stop_words = set(stopwords.words('english'))  # Lista de stopwords \n",
    "    tokens = wordpunct_tokenize(texto)  # Separamos el texto por palabras (tokens)\n",
    "    \n",
    "    # Filtramos las palabras: que no sean stopwords y que sean letras (no signos)\n",
    "    #tokens_filtrados = [p for p in tokens if p.lower() not in stop_words and p.isalpha()]\n",
    "    \n",
    "    # Lematizamos usando como referencia los verbos\n",
    "    lematizadas = [lemmatizer.lemmatize(p, pos='v') for p in tokens]\n",
    "    \n",
    "    # Unimos todo nuevamente en un texto limpio\n",
    "    return ' '.join(lematizadas)\n",
    "\n",
    "# Aplicamos esta limpieza a los datos de entrenamiento y prueba\n",
    "X_train_limpio = X_train.apply(limpiar_texto)\n",
    "X_test_limpio = X_test.apply(limpiar_texto)\n",
    "\n",
    "# Convertimos los textos a vectores usando CountVectorizer\n",
    "vectorizador = CountVectorizer()\n",
    "X_train_vec = vectorizador.fit_transform(X_train_limpio)\n",
    "X_test_vec = vectorizador.transform(X_test_limpio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos y entrenamos el modelo Random Forest\n",
    "modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_rf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Hacemos predicciones y evaluamos el modelo\n",
    "predicciones = modelo_rf.predict(X_test_vec)\n",
    "\n",
    "# Métricas de desempeño\n",
    "accuracy_lemmatizer = accuracy_score(y_test, predicciones)\n",
    "reporte = classification_report(y_test, predicciones)\n",
    "matriz_conf = confusion_matrix(y_test, predicciones)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\" Accuracy del modelo combinado:\", accuracy_lemmatizer)\n",
    "print(\"\\n Reporte de clasificación:\\n\", reporte)\n",
    "print(\"\\n Matriz de confusión:\\n\", matriz_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Multiples técnicas\n",
    "\n",
    "En la celda 4 creen un modelo de random forest con la libreria sklearn que prediga el sentimiento de los tweets usando los set de entrenamiento y test definidos anteriormente. Usen la función **CountVectorizer, eliminen stopwords, lematizen el texto con verbos** y presenten el desempeño del modelo con la métrica del acurracy.\n",
    "\n",
    "Recuerden que el preprocesamiento que se haga sobre los datos de entrenamiento  (*.fit_transform()*) deben ser aplicado al set de test (*.transform()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que limpie el texto\n",
    "# Quitamos palabras vacías y lematizamos las palabras restantes\n",
    "lemmatizer = WordNetLemmatizer()  # Inicializamos el lematizador\n",
    "def limpiar_texto(texto):\n",
    "    stop_words = set(stopwords.words('english'))  # Lista de stopwords \n",
    "    tokens = wordpunct_tokenize(texto)  # Separamos el texto por palabras (tokens)\n",
    "    \n",
    "    # Filtramos las palabras: que no sean stopwords y que sean letras (no signos)\n",
    "    tokens_filtrados = [p for p in tokens if p.lower() not in stop_words and p.isalpha()]\n",
    "    \n",
    "    # Lematizamos usando como referencia los verbos\n",
    "    lematizadas = [lemmatizer.lemmatize(p, pos='v') for p in tokens_filtrados]\n",
    "    \n",
    "    # Unimos todo nuevamente en un texto limpio\n",
    "    return ' '.join(lematizadas)\n",
    "\n",
    "# Aplicamos esta limpieza a los datos de entrenamiento y prueba\n",
    "X_train_limpio = X_train.apply(limpiar_texto)\n",
    "X_test_limpio = X_test.apply(limpiar_texto)\n",
    "\n",
    "# Convertimos los textos a vectores usando CountVectorizer\n",
    "vectorizador = CountVectorizer()\n",
    "X_train_vec = vectorizador.fit_transform(X_train_limpio)\n",
    "X_test_vec = vectorizador.transform(X_test_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos y entrenamos el modelo Random Forest\n",
    "modelo_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "modelo_rf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Hacemos predicciones y evaluamos el modelo\n",
    "predicciones = modelo_rf.predict(X_test_vec)\n",
    "\n",
    "# Métricas de desempeño\n",
    "accuracy_combined= accuracy_score(y_test, predicciones)\n",
    "reporte = classification_report(y_test, predicciones)\n",
    "matriz_conf = confusion_matrix(y_test, predicciones)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\" Accuracy del modelo combinado:\", accuracy)\n",
    "print(\"\\n Reporte de clasificación:\\n\", reporte)\n",
    "print(\"\\n Matriz de confusión:\\n\", matriz_conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Comparación y análisis de resultados\n",
    "\n",
    "En la celda 5 comparen los resultados obtenidos de los diferentes modelos (random forest) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = ['CountVectorizer', 'StopWords', 'Lemmatizer', 'Combined']\n",
    "Accuracy = [accuracy_RF, accuracy_StopWords, accuracy_lemmatizer, accuracy_combined]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "# Color púrpura\n",
    "purple_color = '#800080'\n",
    "\n",
    "# Gráfico: Comparar modelos por MSE\n",
    "bars = ax.bar(modelos, MSE, color=purple_color, alpha=0.7)\n",
    "ax.set_title('Comparación de Modelos por MSE', fontsize=11)\n",
    "ax.set_xlabel('Modelos', fontsize=11)\n",
    "ax.set_ylabel('MSE', fontsize=11)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Mostrar el valor arriba de cada barra\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2.0, height, f'{height:.4f}', \n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Ajustes finales\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
